{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "570dbb57",
   "metadata": {},
   "source": [
    "# Day 5\n",
    "## Pytorch\n",
    "* Build an MLP in Pytorch\n",
    "* Train MNIST/Fashion-MNIST (CPU)\n",
    "* Add weight decay, run with SGD vs Adam, add LR scheduler. \n",
    "\n",
    "### Check: \n",
    "* MNIST: test accuracy > 97% \n",
    "* MLP < 10 epochs (Adam helps)\n",
    "\n",
    "### Interview drill \n",
    "Differences between weight decay and L2 in Adam (decoupled vs classical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3869adcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F  # noqa: N812\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc18583e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEVICE] Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# ---- Configuration ----\n",
    "DATASET = datasets.FashionMNIST\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 10\n",
    "LR = 2e-3\n",
    "WD = 1e-4\n",
    "H = 42\n",
    "COSINE_LR = True # Use cosine learning rate schedule\n",
    "SEED = 42\n",
    "NUM_WORKERS = 2\n",
    "DEVICE = \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"[DEVICE] Using device: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad8a811",
   "metadata": {},
   "source": [
    "## Fashion MNIST data preprocessing\n",
    "\n",
    "**Fashion MNIST** stores pixel values as unsigned 8-bit integers in the range 0...255. Dividing by 255 converts this to floats in $[0,1]$. Necessary before mean/std normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7f0e5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data] Mean: 0.28604060411453247, std: 0.3530242443084717\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_train = datasets.FashionMNIST(root=\"./data\", train=True,  download=True)\n",
    "data = raw_train.data.float().div_(255)\n",
    "mean = data.mean().item()\n",
    "std = data.std().item()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((mean,), (std,)),\n",
    "])\n",
    "\n",
    "# --- Reload datasets with transforms (standard) ---\n",
    "train_ds = datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_ds  = datasets.FashionMNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# --- Data loaders ---\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "\n",
    "print(f\"[Data] Mean: {mean}, std: {std}\")\n",
    "print(\"[Data] Train size:\", len(train_ds))\n",
    "print(\"[Data] Test size:\", len(test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e3e70f",
   "metadata": {},
   "source": [
    "## MLP Implementation\n",
    "\n",
    "*view* - reshapes tensors without copying memory when possible. Pass the new shape, -1: infer dimension automatically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32d0c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nets_numpy import MLP\n",
    "\n",
    "model = MLP(droupout_probability=0.1,\n",
    "            use_batchnorm=False).to(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59b81518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training] Epoch  1/10 | Train loss: 0.2701, accuracy: 0.8987 | Test loss: 0.3326, accuracy: 0.8849 | Learning rate: 0.001951\n",
      "[Model] New best model saved with accuracy: 0.8849\n",
      "[Training] Epoch  2/10 | Train loss: 0.2536, accuracy: 0.9070 | Test loss: 0.3476, accuracy: 0.8771 | Learning rate: 0.001809\n",
      "[Training] Epoch  3/10 | Train loss: 0.2448, accuracy: 0.9078 | Test loss: 0.3247, accuracy: 0.8853 | Learning rate: 0.001588\n",
      "[Model] New best model saved with accuracy: 0.8853\n",
      "[Training] Epoch  4/10 | Train loss: 0.2247, accuracy: 0.9149 | Test loss: 0.3235, accuracy: 0.8870 | Learning rate: 0.001309\n",
      "[Model] New best model saved with accuracy: 0.8870\n",
      "[Training] Epoch  5/10 | Train loss: 0.2086, accuracy: 0.9208 | Test loss: 0.3148, accuracy: 0.8909 | Learning rate: 0.001000\n",
      "[Model] New best model saved with accuracy: 0.8909\n",
      "[Training] Epoch  6/10 | Train loss: 0.1916, accuracy: 0.9260 | Test loss: 0.3096, accuracy: 0.8925 | Learning rate: 0.000691\n",
      "[Model] New best model saved with accuracy: 0.8925\n",
      "[Training] Epoch  7/10 | Train loss: 0.1704, accuracy: 0.9354 | Test loss: 0.3072, accuracy: 0.8963 | Learning rate: 0.000412\n",
      "[Model] New best model saved with accuracy: 0.8963\n",
      "[Training] Epoch  8/10 | Train loss: 0.1566, accuracy: 0.9402 | Test loss: 0.3120, accuracy: 0.8974 | Learning rate: 0.000191\n",
      "[Model] New best model saved with accuracy: 0.8974\n",
      "[Training] Epoch  9/10 | Train loss: 0.1460, accuracy: 0.9450 | Test loss: 0.3090, accuracy: 0.9006 | Learning rate: 0.000049\n",
      "[Model] New best model saved with accuracy: 0.9006\n",
      "[Training] Epoch 10/10 | Train loss: 0.1394, accuracy: 0.9476 | Test loss: 0.3092, accuracy: 0.9006 | Learning rate: 0.000000\n",
      "[Model] Best accuracy: 0.9006\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from utils import train_epoch, evaluate\n",
    "\n",
    "# ---- Optimizer/Loss ---- \n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS) if COSINE_LR else None\n",
    "\n",
    "# --- Training loop ---\n",
    "best_accuracy = 0.0\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    train_loss, train_accuracy = train_epoch(model, train_loader, optimizer, loss)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader, loss)\n",
    "\n",
    "    if scheduler: scheduler.step()\n",
    "\n",
    "    print(f\"[Training] Epoch {epoch:2d}/{epochs} | \"\n",
    "          f\"Train loss: {train_loss:.4f}, accuracy: {train_accuracy:.4f} | \"\n",
    "          f\"Test loss: {test_loss:.4f}, accuracy: {test_accuracy:.4f} | \"\n",
    "          f\"Learning rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "        torch.save(model.state_dict(), \"fashion_mnist_mlp_best.pth\")\n",
    "        print(f\"[Model] New best model saved with accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "print(f\"[Model] Best accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5273bff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test acc: 90.06%\n",
      "\n",
      "Per-class accuracy:\n",
      "   0 (T-shirt/top ): 86.40%\n",
      "   1 (Trouser     ): 98.00%\n",
      "   2 (Pullover    ): 82.40%\n",
      "   3 (Dress       ): 90.30%\n",
      "   4 (Coat        ): 85.40%\n",
      "   5 (Sandal      ): 96.60%\n",
      "   6 (Shirt       ): 71.10%\n",
      "   7 (Sneaker     ): 96.90%\n",
      "   8 (Bag         ): 97.30%\n",
      "   9 (Ankle boot  ): 96.20%\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "[[864   2  10  15   5   2  97   0   5   0]\n",
      " [  3 980   1  12   2   0   2   0   0   0]\n",
      " [ 20   1 824  10  77   0  67   0   1   0]\n",
      " [ 15   8  14 903  33   1  22   0   4   0]\n",
      " [  1   0  72  28 854   0  44   0   1   0]\n",
      " [  0   0   0   0   0 966   0  17   0  17]\n",
      " [111   0  80  25  67   0 711   0   6   0]\n",
      " [  0   0   0   0   0  11   0 969   1  19]\n",
      " [  5   0   1   5   1   4   5   5 973   1]\n",
      " [  0   1   0   0   0   4   1  32   0 962]]\n"
     ]
    }
   ],
   "source": [
    "# Recompute once for final confusion matrix/readout\n",
    "_, test_acc, c, per_class_acc = evaluate(model, test_loader, loss, compute_confmat=True)\n",
    "print(f\"Final test acc: {test_acc*100:.2f}%\")\n",
    "\n",
    "# Pretty-print per-class accuracy\n",
    "print(\"\\nPer-class accuracy:\")\n",
    "CLASS_NAMES = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]\n",
    "for i, acc in enumerate(per_class_acc):\n",
    "    print(f\"  {i:>2} ({CLASS_NAMES[i]:12s}): {acc*100:5.2f}%\")\n",
    "\n",
    "print(\"\\nConfusion matrix (rows=true, cols=pred):\")\n",
    "print(c.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
