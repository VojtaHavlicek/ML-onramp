{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1b64b6c",
   "metadata": {},
   "source": [
    "# Data Analysis using the FI-2010 dataset\n",
    "\n",
    "* FI-2010 is a [publicly available dataset](https://arxiv.org/abs/1705.03233) for mid-price forecasting from limit order book data. \n",
    "\n",
    "* Five stocks from NASDAQ Nordic stock market for 10 consecutive days. About 4000000 samples in total. \n",
    "\n",
    "\n",
    "## The data: \n",
    "```text\n",
    ".\n",
    "└── BenchmarkDatasets\n",
    "    └── BenchmarkDatasets\n",
    "        ├── Auction\n",
    "        │   ├── 1.Auction_Zscore\n",
    "        │   │   ├── Auction_Zscore_Testing\n",
    "        │   │   └── Auction_Zscore_Training\n",
    "        │   ├── 2.Auction_MinMax\n",
    "        │   │   ├── Auction_MinMax_Testing\n",
    "        │   │   └── Auction_MinMax_Training\n",
    "        │   └── 3.Auction_DecPre\n",
    "        │       ├── Auction_DecPre_Testing\n",
    "        │       └── Auction_DecPre_Training\n",
    "        └── NoAuction\n",
    "            ├── 1.NoAuction_Zscore\n",
    "            │   ├── NoAuction_Zscore_Testing\n",
    "            │   └── NoAuction_Zscore_Training\n",
    "            ├── 2.NoAuction_MinMax\n",
    "            │   ├── NoAuction_MinMax_Testing\n",
    "            │   └── NoAuction_MinMax_Training\n",
    "            └── 3.NoAuction_DecPre\n",
    "                ├── NoAuction_DecPre_Testing\n",
    "                └── NoAuction_DecPre_Training\n",
    "```\n",
    "\n",
    "FI-2010 Benchmark datasets release that is bundled with multiple preprocessed versions of the LOB. The folder names: \n",
    "\n",
    "\n",
    "### Has Auction?\n",
    "* **Auction** Auction includes samples from opening and closing auctions of the day. These behave differently from continuous trading and contain large batch orders or jumps in price. \n",
    "\n",
    "* **NoAuction** This removes auction periods, leaving only continuous trading hours. A *cleaner* dataset. \n",
    "\n",
    "## Zscore, MinMax, DecPre\n",
    "Preprocessing and normalization schemes. How was the limit order book normalized before written out. \n",
    "\n",
    "* **Zscore:** \n",
    "    * each feature has been standardized: $$x' = \\frac{x-\\mu}{\\sigma}$$.\n",
    "    * zero mean, unit variance.\n",
    "    * helps convergence.\n",
    "\n",
    "* **MinMax:**\n",
    "    * Each feature scaled to [0,1]\n",
    "    * Preserves shape of the distribution, sensitive to outliers\n",
    "\n",
    "* **DecPre:**\n",
    "    * Prices divided by a fixed constant to reduce decimal precision\n",
    "    * Input is smaller and easier without relying on per-feature statistics.\n",
    "    * Sometimes used in microstructure studies.\n",
    "\n",
    "\n",
    "### For XGBoost -> Transformer pipeline, \n",
    "Start with **NoAuction** data and **ZScore**. \n",
    "\n",
    "```text\n",
    ".\n",
    "├── NoAuction_Zscore_Testing\n",
    "│   ├── Test_Dst_NoAuction_ZScore_CF_1.txt\n",
    "│   ├── Test_Dst_NoAuction_ZScore_CF_2.txt\n",
    "│   ├── Test_Dst_NoAuction_ZScore_CF_3.txt\n",
    "│   ├── Test_Dst_NoAuction_ZScore_CF_4.txt\n",
    "│   ├── Test_Dst_NoAuction_ZScore_CF_5.txt\n",
    "│   ├── Test_Dst_NoAuction_ZScore_CF_6.txt\n",
    "│   ├── Test_Dst_NoAuction_ZScore_CF_7.txt\n",
    "│   ├── Test_Dst_NoAuction_ZScore_CF_8.txt\n",
    "│   └── Test_Dst_NoAuction_ZScore_CF_9.txt\n",
    "└── NoAuction_Zscore_Training\n",
    "    ├── Train_Dst_NoAuction_ZScore_CF_1.txt\n",
    "    ├── Train_Dst_NoAuction_ZScore_CF_2.txt\n",
    "    ├── Train_Dst_NoAuction_ZScore_CF_3.txt\n",
    "    ├── Train_Dst_NoAuction_ZScore_CF_4.txt\n",
    "    ├── Train_Dst_NoAuction_ZScore_CF_5.txt\n",
    "    ├── Train_Dst_NoAuction_ZScore_CF_6.txt\n",
    "    ├── Train_Dst_NoAuction_ZScore_CF_7.txt\n",
    "    ├── Train_Dst_NoAuction_ZScore_CF_8.txt\n",
    "    └── Train_Dst_NoAuction_ZScore_CF_9.txt\n",
    "```\n",
    "\n",
    "One sample per row. Last column is the label (-1/0/1 or 0/1/2 based on preprocessing). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc3c23f",
   "metadata": {},
   "source": [
    "## Loader and Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "002d7b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re \n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_FI2010_split(train_dir, test_dir):\n",
    "    def load_folder(folder):\n",
    "        print(f\"Loading folder {folder}\")\n",
    "        all_files = glob.glob(os.path.join(folder, \"*.txt\"))\n",
    "        \n",
    "        data_list = []\n",
    "        for file in tqdm(all_files):\n",
    "            print(f\"Loading {file}\")\n",
    "            df = pd.read_csv(file, header=None, delim_whitespace=True)\n",
    "            data_list.append(df)\n",
    "        big = pd.concat(data_list, axis=0, ignore_index=True)\n",
    "        return big\n",
    "    \n",
    "    train_df = load_folder(train_dir)\n",
    "    test_df = load_folder(test_dir)\n",
    "\n",
    "    X_train = train_df.iloc[:, :-1].astype(np.float32).values\n",
    "    y_train = train_df.iloc[:, -1].astype(np.int64).values\n",
    "\n",
    "    X_test = test_df.iloc[:, :-1].astype(np.float32).values\n",
    "    y_test = test_df.iloc[:, -1].astype(np.int64).values\n",
    "\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "train_dir = \"published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Training\"\n",
    "test_dir = \"published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "215030f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading folder published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Training/Train_Dst_NoAuction_ZScore_CF_8.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wm/3n4z6f854gjfgn3qgq832k140000gn/T/ipykernel_38397/3729895683.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(file, header=None, delim_whitespace=True)\n",
      " 11%|█         | 1/9 [01:39<13:18, 99.82s/it]/var/folders/wm/3n4z6f854gjfgn3qgq832k140000gn/T/ipykernel_38397/3729895683.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(file, header=None, delim_whitespace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Training/Train_Dst_NoAuction_ZScore_CF_9.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [05:33<20:48, 178.32s/it]/var/folders/wm/3n4z6f854gjfgn3qgq832k140000gn/T/ipykernel_38397/3729895683.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(file, header=None, delim_whitespace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Training/Train_Dst_NoAuction_ZScore_CF_2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3/9 [05:40<10:00, 100.10s/it]/var/folders/wm/3n4z6f854gjfgn3qgq832k140000gn/T/ipykernel_38397/3729895683.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(file, header=None, delim_whitespace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Training/Train_Dst_NoAuction_ZScore_CF_3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [05:49<05:21, 64.37s/it] /var/folders/wm/3n4z6f854gjfgn3qgq832k140000gn/T/ipykernel_38397/3729895683.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(file, header=None, delim_whitespace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Training/Train_Dst_NoAuction_ZScore_CF_1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5/9 [05:51<02:47, 41.95s/it]/var/folders/wm/3n4z6f854gjfgn3qgq832k140000gn/T/ipykernel_38397/3729895683.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(file, header=None, delim_whitespace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Training/Train_Dst_NoAuction_ZScore_CF_4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6/9 [06:15<01:47, 35.67s/it]/var/folders/wm/3n4z6f854gjfgn3qgq832k140000gn/T/ipykernel_38397/3729895683.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(file, header=None, delim_whitespace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Training/Train_Dst_NoAuction_ZScore_CF_5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7/9 [06:44<01:07, 33.55s/it]/var/folders/wm/3n4z6f854gjfgn3qgq832k140000gn/T/ipykernel_38397/3729895683.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(file, header=None, delim_whitespace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Training/Train_Dst_NoAuction_ZScore_CF_7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8/9 [08:06<00:48, 48.84s/it]/var/folders/wm/3n4z6f854gjfgn3qgq832k140000gn/T/ipykernel_38397/3729895683.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(file, header=None, delim_whitespace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Training/Train_Dst_NoAuction_ZScore_CF_6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [09:15<00:00, 61.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading folder published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_ZScore_CF_1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wm/3n4z6f854gjfgn3qgq832k140000gn/T/ipykernel_38397/3729895683.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(file, header=None, delim_whitespace=True)\n",
      " 11%|█         | 1/9 [00:02<00:16,  2.12s/it]/var/folders/wm/3n4z6f854gjfgn3qgq832k140000gn/T/ipykernel_38397/3729895683.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(file, header=None, delim_whitespace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_ZScore_CF_3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [00:04<00:14,  2.07s/it]/var/folders/wm/3n4z6f854gjfgn3qgq832k140000gn/T/ipykernel_38397/3729895683.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(file, header=None, delim_whitespace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_ZScore_CF_2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3/9 [00:05<00:09,  1.59s/it]/var/folders/wm/3n4z6f854gjfgn3qgq832k140000gn/T/ipykernel_38397/3729895683.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(file, header=None, delim_whitespace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_ZScore_CF_6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [00:07<00:08,  1.79s/it]/var/folders/wm/3n4z6f854gjfgn3qgq832k140000gn/T/ipykernel_38397/3729895683.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(file, header=None, delim_whitespace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_ZScore_CF_7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5/9 [00:10<00:08,  2.24s/it]/var/folders/wm/3n4z6f854gjfgn3qgq832k140000gn/T/ipykernel_38397/3729895683.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(file, header=None, delim_whitespace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_ZScore_CF_5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6/9 [00:12<00:06,  2.21s/it]/var/folders/wm/3n4z6f854gjfgn3qgq832k140000gn/T/ipykernel_38397/3729895683.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(file, header=None, delim_whitespace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_ZScore_CF_4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7/9 [00:14<00:04,  2.11s/it]/var/folders/wm/3n4z6f854gjfgn3qgq832k140000gn/T/ipykernel_38397/3729895683.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(file, header=None, delim_whitespace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_ZScore_CF_9.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8/9 [00:16<00:01,  1.99s/it]/var/folders/wm/3n4z6f854gjfgn3qgq832k140000gn/T/ipykernel_38397/3729895683.py:16: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(file, header=None, delim_whitespace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading published/BenchmarkDatasets/BenchmarkDatasets/NoAuction/1.NoAuction_Zscore/NoAuction_Zscore_Testing/Test_Dst_NoAuction_ZScore_CF_8.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:19<00:00,  2.11s/it]\n"
     ]
    },
    {
     "ename": "IntCastingNaNError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIntCastingNaNError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m (X_train, y_train), (X_test, y_test) = \u001b[43mload_FI2010_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mload_FI2010_split\u001b[39m\u001b[34m(train_dir, test_dir)\u001b[39m\n\u001b[32m     22\u001b[39m test_df = load_folder(test_dir)\n\u001b[32m     24\u001b[39m X_train = train_df.iloc[:, :-\u001b[32m1\u001b[39m].astype(np.float32).values\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m y_train = \u001b[43mtrain_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mint64\u001b[49m\u001b[43m)\u001b[49m.values\n\u001b[32m     27\u001b[39m X_test = test_df.iloc[:, :-\u001b[32m1\u001b[39m].astype(np.float32).values\n\u001b[32m     28\u001b[39m y_test = test_df.iloc[:, -\u001b[32m1\u001b[39m].astype(np.int64).values\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/onramp/.venv/lib/python3.13/site-packages/pandas/core/generic.py:6662\u001b[39m, in \u001b[36mNDFrame.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m   6656\u001b[39m     results = [\n\u001b[32m   6657\u001b[39m         ser.astype(dtype, copy=copy, errors=errors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.items()\n\u001b[32m   6658\u001b[39m     ]\n\u001b[32m   6660\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6661\u001b[39m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6662\u001b[39m     new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6663\u001b[39m     res = \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(new_data, axes=new_data.axes)\n\u001b[32m   6664\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mastype\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/onramp/.venv/lib/python3.13/site-packages/pandas/core/internals/managers.py:430\u001b[39m, in \u001b[36mBaseBlockManager.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[32m    428\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mastype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[43m=\u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/onramp/.venv/lib/python3.13/site-packages/pandas/core/internals/managers.py:363\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    366\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/onramp/.venv/lib/python3.13/site-packages/pandas/core/internals/blocks.py:784\u001b[39m, in \u001b[36mBlock.astype\u001b[39m\u001b[34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[39m\n\u001b[32m    781\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan not squeeze with more than one column.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    782\u001b[39m     values = values[\u001b[32m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m new_values = \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    786\u001b[39m new_values = maybe_coerce_values(new_values)\n\u001b[32m    788\u001b[39m refs = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/onramp/.venv/lib/python3.13/site-packages/pandas/core/dtypes/astype.py:237\u001b[39m, in \u001b[36mastype_array_safe\u001b[39m\u001b[34m(values, dtype, copy, errors)\u001b[39m\n\u001b[32m    234\u001b[39m     dtype = dtype.numpy_dtype\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     new_values = \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/onramp/.venv/lib/python3.13/site-packages/pandas/core/dtypes/astype.py:182\u001b[39m, in \u001b[36mastype_array\u001b[39m\u001b[34m(values, dtype, copy)\u001b[39m\n\u001b[32m    179\u001b[39m     values = values.astype(dtype, copy=copy)\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     values = \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np.dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values.dtype.type, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/onramp/.venv/lib/python3.13/site-packages/pandas/core/dtypes/astype.py:101\u001b[39m, in \u001b[36m_astype_nansafe\u001b[39m\u001b[34m(arr, dtype, copy, skipna)\u001b[39m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.ensure_string_array(\n\u001b[32m     97\u001b[39m         arr, skipna=skipna, convert_na_value=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     98\u001b[39m     ).reshape(shape)\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m np.issubdtype(arr.dtype, np.floating) \u001b[38;5;129;01mand\u001b[39;00m dtype.kind \u001b[38;5;129;01min\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33miu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_astype_float_to_int_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m arr.dtype == \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m    104\u001b[39m     \u001b[38;5;66;03m# if we have a datetime/timedelta array of objects\u001b[39;00m\n\u001b[32m    105\u001b[39m     \u001b[38;5;66;03m# then coerce to datetime64[ns] and use DatetimeArray.astype\u001b[39;00m\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m lib.is_np_dtype(dtype, \u001b[33m\"\u001b[39m\u001b[33mM\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/onramp/.venv/lib/python3.13/site-packages/pandas/core/dtypes/astype.py:145\u001b[39m, in \u001b[36m_astype_float_to_int_nansafe\u001b[39m\u001b[34m(values, dtype, copy)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[33;03mastype with a check preventing converting NaN to an meaningless integer value.\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.isfinite(values).all():\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m IntCastingNaNError(\n\u001b[32m    146\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot convert non-finite values (NA or inf) to integer\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    147\u001b[39m     )\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype.kind == \u001b[33m\"\u001b[39m\u001b[33mu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    149\u001b[39m     \u001b[38;5;66;03m# GH#45151\u001b[39;00m\n\u001b[32m    150\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (values >= \u001b[32m0\u001b[39m).all():\n",
      "\u001b[31mIntCastingNaNError\u001b[39m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = load_FI2010_split(train_dir, test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c88fe0",
   "metadata": {},
   "source": [
    "**TODO:** finish the parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe85f3d",
   "metadata": {},
   "source": [
    "## Reading preprocessed CSVs instead? \n",
    "\n",
    "I am assuming that these are ZScore without auction data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db242d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('FI2010_train.csv', header=0, index_col=0)\n",
    "test = pd.read_csv('FI2010_test.csv', header=0, index_col=0)\n",
    "\n",
    "X_train = train.iloc[:, :-1].astype(np.float32)\n",
    "y_train = train.iloc[:, -1].astype(np.int64)\n",
    "\n",
    "X_test = test.iloc[:, :-1].astype(np.float32)\n",
    "y_test = test.iloc[:, -1].astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0a75e4",
   "metadata": {},
   "source": [
    "### Features\n",
    "\n",
    "#### Confirm this is the ZScore normalized one: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8c6bdd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "89d8fd48-d19d-4e4a-a02f-65af7f09b4a5",
       "rows": [
        [
         "count",
         "362400.0"
        ],
        [
         "mean",
         "2.1557671203709106e-08"
        ],
        [
         "std",
         "1.0"
        ],
        [
         "min",
         "-1.0656219720840454"
        ],
        [
         "25%",
         "-0.9833033680915833"
        ],
        [
         "50%",
         "-0.5266305804252625"
        ],
        [
         "75%",
         "1.1560026407241821"
        ],
        [
         "max",
         "1.3559194803237915"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 8
       }
      },
      "text/plain": [
       "count    3.624000e+05\n",
       "mean     2.155767e-08\n",
       "std      1.000000e+00\n",
       "min     -1.065622e+00\n",
       "25%     -9.833034e-01\n",
       "50%     -5.266306e-01\n",
       "75%      1.156003e+00\n",
       "max      1.355919e+00\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "feature_0 = X_train.loc[:, '0']\n",
    "feature_0.describe() # <---- ZScore standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f2665a",
   "metadata": {},
   "source": [
    "#### Are there any Nan's? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fcf4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train nans: False\n",
      "X_test nans: False\n",
      "y_train nans: False\n",
      "y_test nans: False\n"
     ]
    }
   ],
   "source": [
    "# Checks for NaNs\n",
    "print(f\"X_train nans: {X_train.isna().any().any()}\")\n",
    "print(f\"X_test nans: {X_test.isna().any().any()}\")\n",
    "print(f\"y_train nans: {y_train.isna().any().any()}\")\n",
    "print(f\"y_test nans: {y_test.isna().any().any()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aefd8f",
   "metadata": {},
   "source": [
    "### Target vars\n",
    "The original datasets use: \n",
    "* 1 -> Down\n",
    "* 2 -> Stationary\n",
    "* 3 -> Up\n",
    "\n",
    "Remap y = y-1 to use 0,1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "485bc8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT to remap y to 0,1,2\n",
    "# y_test = y_test - 1 \n",
    "# y_train = y_train - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "97109f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 0]), array([1, 0, 2]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -> target vars:\n",
    "y_test.unique(), y_train.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3a39e2",
   "metadata": {},
   "source": [
    "#### Sanity check\n",
    "\n",
    "FI-2010 rows are LOB snapshots. The first two columns are typically the best ask price and ask volumne, the next two are best bid and bid volumne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b55cd760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mid(df):\n",
    "    best_ask = df.iloc[:, 0]\n",
    "    best_bid = df.iloc[:, 2]\n",
    "    mid = (best_ask + best_bid) / 2\n",
    "    return mid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bac0ef",
   "metadata": {},
   "source": [
    "Direction mid price $k$ steps ahead. \n",
    "\n",
    "**No nice signal.** Chad says: \n",
    "\n",
    "That’s actually a super interesting finding 👍 — it means the labels in your preprocessed CSV are not computed on-the-fly from best bid/ask, but were baked in during preprocessing. That’s exactly how the FI-2010 BenchmarkDatasets were released:\n",
    "\n",
    "They took the raw LOBSTER/ITCH order book.\n",
    "\n",
    "They defined the label as mid-price movement after 10 events (not 10 rows in the normalized file, but 10 events in the original event stream).\n",
    "\n",
    "Then they normalized everything (Z-score, MinMax, DecPre) and saved feature + label together.\n",
    "\n",
    "👉 So if you try to recompute labels just from your normalized CSV, they won’t line up — you’ve lost the raw event stream ordering. That’s why you don’t see agreement even with longer lags. \n",
    "\n",
    "And that's ausome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2474b634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_from_mid(mid:pd.Series, horizon=10, eps:float=1e-5):\n",
    "    future_mid = mid.shift(-horizon)\n",
    "    diff = future_mid - mid\n",
    "    labels = pd.Series(1, index=mid.index)  # Default to 0 (down)\n",
    "    labels[diff > eps] = 0  # Up\n",
    "    labels[diff < -eps] = 2  # Stationary\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "66d1ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = compute_mid(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6392258a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horizon: 1, Accuracy: 0.3568\n",
      "Horizon: 3, Accuracy: 0.4252\n",
      "Horizon: 5, Accuracy: 0.4579\n",
      "Horizon: 7, Accuracy: 0.4735\n",
      "Horizon: 9, Accuracy: 0.4801\n",
      "Horizon: 11, Accuracy: 0.4833\n",
      "Horizon: 13, Accuracy: 0.4837\n",
      "Horizon: 15, Accuracy: 0.4826\n",
      "Horizon: 17, Accuracy: 0.4800\n",
      "Horizon: 19, Accuracy: 0.4770\n"
     ]
    }
   ],
   "source": [
    "mid\n",
    "\n",
    "for horizon in range(1, 21, 2):\n",
    "    y_derived = labels_from_mid(mid, horizon=horizon, eps=1e-5)\n",
    "    accuracy = (y_derived == y_train).mean()\n",
    "    print(f\"Horizon: {horizon}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503545fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab287b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5e4ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
