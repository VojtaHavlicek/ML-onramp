{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "995f162e",
   "metadata": {},
   "source": [
    "# Day 2\n",
    "\n",
    "## Dataloader\n",
    "Desiderata:\n",
    "* Work with any dataset implementing __len__ and __getitem(i)\n",
    "* Deterministic shuffling. Reproducible via seed and per-epoch control, no data leakage\n",
    "* Batching controls: batch_size, drop_last\n",
    "* Collation: can stack NumPy arrays, recursibely handle tuples/lists/dicts.\n",
    "* Length semantics: len(dataloader) returns number of batches\n",
    "* Memory-friendly: no data copying\n",
    "* Composability: ? \n",
    "* Per-epoch reseeding\n",
    "* Clear errors: shape/length mismatches fail loudly\n",
    "* Samplers, prefetch..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6762b159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, List, Sequence, Union, Tuple, Dict, Optional\n",
    "import numpy as np\n",
    "\n",
    "class DatasetProtocol:\n",
    "    \"\"\"Any dataset with __len__ and __getitem__ is acceptable for the dataloader.\"\"\"\n",
    "\n",
    "    def __len__(self) -> int: ... # noqa: D105, Convention in typing is to uses ellipsis (...) \n",
    "    def __getitem__(self, idx: int) -> Any: ... # noqa: ANN401, D105\n",
    "\n",
    "def _default_collate(batch: List[Any]) -> Any:\n",
    "    \"\"\"Collate: to take multiple individual samples from the dataset and\n",
    "    assemble them in to a single batch in the format the model expects.\n",
    "    Stacks numpy arrays along a new first dimension when shapes match.\n",
    "    Recursively handles tuples, lists and dicts.\n",
    "\n",
    "    Args:\n",
    "        batch (List[Any]): List of samples from the dataset.\n",
    "\n",
    "    Returns:\n",
    "        Any: Collated batch, which can be a numpy array, tuple, list\n",
    "\n",
    "    \"\"\" # noqa: D205\n",
    "    elem = batch[0]\n",
    "\n",
    "    # numpy arrays\n",
    "    if isinstance(elem, np.ndarray):\n",
    "        # Verify shapes match\n",
    "        shapes = [x.shape for x in batch]\n",
    "        if not all(s == shapes[0] for s in shapes):\n",
    "            raise ValueError(f\"Array shapes differ in batch: {shapes}\")\n",
    "        return np.stack(batch, axis=0)\n",
    "\n",
    "    # numbers\n",
    "    if isinstance(elem, (int, float, np.integer, np.floating)):\n",
    "        return np.array(batch)\n",
    "\n",
    "    # tuples\n",
    "    if isinstance(elem, tuple): \n",
    "        transposed = list(zip(*batch))\n",
    "        return tuple(_default_collate(list(x)) for x in transposed)\n",
    "\n",
    "    # lists\n",
    "    if isinstance(elem, list):\n",
    "        transposed = list(zip(*batch))\n",
    "        return [_default_collate(list(x)) for x in transposed]\n",
    "\n",
    "    # dicts\n",
    "    if isinstance(elem, dict):\n",
    "        keys = elem.keys()\n",
    "        if not all(d.keys() == keys for d in batch):\n",
    "            raise ValueError(\"All dict samples must have the same keys.\") #noqa:TRY003, EM101\n",
    "        return {k: _default_collate([d[k] for d in batch]) for k in keys}\n",
    "\n",
    "    return batch  # If no known type, return as is\n",
    "\n",
    "\n",
    "class Dataloader: \n",
    "    \"\"\"Training data management class.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 dataset: DatasetProtocol,\n",
    "                 batch_size: int = 32,\n",
    "                 shuffle: bool = True,\n",
    "                 drop_last: bool = False,\n",
    "                 collate_fn: Optional[Callable[[List[Any]], Any]] = None,\n",
    "                 seed: Optional[int] = 42,\n",
    "                 indices: Optional[Sequence[int]] = None,\n",
    "                 ):\n",
    "        if batch_size <= 0:\n",
    "             raise ValueError(\"batch size must be positive\")\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.drop_last = drop_last \n",
    "        self.collate_fn = collate_fn or _default_collate\n",
    "        self.base_seed = seed\n",
    "        self.epoch = 0\n",
    "\n",
    "        n = len(dataset)\n",
    "        if indices is None:\n",
    "            self.indices = np.arange(n, dtype=int)\n",
    "        else:\n",
    "            self.indices = np.array(indices, dtype=np.int64)\n",
    "            if np.any(self.indices < 0) or np.any(self.indices >= n):\n",
    "                raise ValueError(\"indices out of bouds\")\n",
    "\n",
    "        self._compute_num_batches()\n",
    "\n",
    "\n",
    "    def _compute_num_batches(self):\n",
    "        N = len(self.indices)\n",
    "        if self.drop_last:\n",
    "            self.num_batches = N // self.batch_size\n",
    "        else: \n",
    "            self.num_batches = (N + self.base_seed - 1) // self.batch_size\n",
    "\n",
    "\n",
    "    def set_epoch(self, epoch:int):\n",
    "        \"\"\"Set curretnt epoch (affects shuffle RNG state deterministically.)\"\"\"\n",
    "        self.epoch = int(epoch)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.num_batches\n",
    "\n",
    "    def __iter__(self):\n",
    "        order = self.indices.copy() \n",
    "        if self.shuffle:\n",
    "            rng = np.random.default_rng(None if self.base_seed else self.base_seed + self.epoch)\n",
    "            rng.shuffle(order)\n",
    "\n",
    "        N = len(order)\n",
    "        bs = self.batch_size\n",
    "        limit = (N // bs) * bs if self.drop_last else N\n",
    "\n",
    "        for start in range(0, limit, bs):\n",
    "            end = min(start + bs, N)\n",
    "            batch_indices = order[start:end].tolist() \n",
    "            batch_samples = [self.dataset[i] for i in batch_indices]\n",
    "            yield self.collate_fn(batch_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1bddcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dataloader] Epoch 0\n",
      "[Dataloader]\n",
      "[Batch] X: \n",
      " [[ 6.  7.]\n",
      " [14. 15.]\n",
      " [12. 13.]\n",
      " [ 4.  5.]] \n",
      "[Batch] y:\n",
      " [1 1 1 0] \n",
      "\n",
      "[Dataloader]\n",
      "[Batch] X: \n",
      " [[ 0.  1.]\n",
      " [18. 19.]\n",
      " [ 2.  3.]\n",
      " [10. 11.]] \n",
      "[Batch] y:\n",
      " [0 1 0 1] \n",
      "\n",
      "[Dataloader]\n",
      "[Batch] X: \n",
      " [[16. 17.]\n",
      " [ 8.  9.]] \n",
      "[Batch] y:\n",
      " [1 1] \n",
      "\n",
      "\n",
      "[Dataloader] Epoch 1\n",
      "[Dataloader]\n",
      "[Batch] X: \n",
      " [[ 8.  9.]\n",
      " [ 6.  7.]\n",
      " [ 2.  3.]\n",
      " [14. 15.]] \n",
      "[Batch] y:\n",
      " [1 1 0 1] \n",
      "\n",
      "[Dataloader]\n",
      "[Batch] X: \n",
      " [[18. 19.]\n",
      " [ 4.  5.]\n",
      " [10. 11.]\n",
      " [ 0.  1.]] \n",
      "[Batch] y:\n",
      " [1 0 1 0] \n",
      "\n",
      "[Dataloader]\n",
      "[Batch] X: \n",
      " [[16. 17.]\n",
      " [12. 13.]] \n",
      "[Batch] y:\n",
      " [1 1] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ArrayDataset(DatasetProtocol):\n",
    "    \"\"\"Simple dataset that wraps a numpy array.\"\"\"\n",
    "\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray): \n",
    "        if len(X) != len(y):\n",
    "            raise ValueError(\"X and y must have the same length.\")\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self) -> int: return len(self.X)\n",
    "    def __getitem__(self, i) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        return (self.X[i], self.y[i])\n",
    "    \n",
    "X = np.arange(20).reshape(10, 2).astype(np.float32)\n",
    "y = (np.sum(X, axis=1) > 10).astype(np.int64)  # Binary classification\n",
    "\n",
    "ds = ArrayDataset(X, y)\n",
    "loader = Dataloader(ds, batch_size=4, shuffle=True, drop_last=False, seed=42)\n",
    "\n",
    "for epoch in range(2):\n",
    "    loader.set_epoch(epoch)\n",
    "    print(f\"\\n[Dataloader] Epoch {epoch}\")\n",
    "    for batch in loader: \n",
    "        xb, yb = batch\n",
    "        print(f\"[Dataloader]\\n[Batch] X: \\n {xb} \\n[Batch] y:\\n {yb} \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1c8ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
